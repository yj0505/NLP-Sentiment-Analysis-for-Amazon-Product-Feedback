{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1752328",
   "metadata": {},
   "source": [
    "# Amazon Reviews — Pipeline Version (TF‑IDF + Logistic & Random Forest)\n",
    "End‑to‑end scikit‑learn Pipelines for text classification using TF‑IDF. Includes Logistic Regression and Random Forest with shared preprocessing, evaluation, ROC curves, Importance feature analysis and save/load examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d726df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk, re, joblib\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, roc_auc_score, classification_report, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86819584",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Load data (adjust path if needed) ===\n",
    "csv_path = r'D:\\NLP_sentiment\\Reviews.csv' \n",
    "df = pd.read_csv(csv_path)\n",
    "print(df.shape)\n",
    "# Create sentiment label: >3 -> positive else negative\n",
    "df[\"Sentiment\"] = df[\"Score\"].apply(lambda s: \"positive\" if s > 3 else \"negative\")\n",
    "df = df[[\"Score\", \"Sentiment\", \"Summary\", \"Text\"]].dropna(subset=[\"Summary\", \"Score\"]).copy()\n",
    "df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef90f45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Text cleaning ===\n",
    "snow = SnowballStemmer('english')\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def clean_text(sentence):\n",
    "    sentence = str(sentence)\n",
    "    sentence = sentence.lower()  # lower case\n",
    "    sentence = re.sub(r'[?|!|.|,|)|(|\\|/]', ' ', sentence)  # replace these punctuation with space\n",
    "    tokens = sentence.split()\n",
    "    out = []\n",
    "    for t in tokens:\n",
    "        out.append(snow.stem(t))\n",
    "    out = \" \".join(out)\n",
    "    out = re.sub(r'[\\'+\"'\"+\"|\"|#]\", '', out)  # remove these punctuation\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef31216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Train / Test split ===\n",
    "X = df[\"Summary\"]            # raw text; cleaning runs inside vectorizer\n",
    "y = df[\"Sentiment\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "X_train.shape, X_test.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8cf9528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Build Pipelines ===\n",
    "# Shared TF-IDF configuration\n",
    "tfidf = TfidfVectorizer(\n",
    "    preprocessor=clean_text,  # run same cleaning at train & inference\n",
    "    ngram_range=(1, 2),\n",
    "    max_features=50_000,\n",
    "    min_df=2\n",
    ")\n",
    "\n",
    "# 1) Logistic Regression pipeline\n",
    "logreg_pipe = Pipeline([\n",
    "    (\"tfidf\", tfidf),\n",
    "    (\"clf\", LogisticRegression(\n",
    "        solver=\"saga\",\n",
    "        class_weight=\"balanced\",\n",
    "        max_iter=2000,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "# 2) Random Forest pipeline\n",
    "# Note: RF on high-dimensional sparse TF-IDF can be heavy; we cap depth/features for speed.\n",
    "rf_pipe = Pipeline([\n",
    "    (\"tfidf\", tfidf),\n",
    "    (\"clf\", RandomForestClassifier(\n",
    "        n_estimators=200,\n",
    "        max_depth=20,\n",
    "        max_features=\"sqrt\",\n",
    "        class_weight=\"balanced_subsample\",\n",
    "        n_jobs=-1,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb852a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Train both models ===\n",
    "logreg_pipe.fit(X_train, y_train)\n",
    "rf_pipe.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e29706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Evaluate ===\n",
    "def evaluate_model(name, pipe, X_test, y_test):\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    # For probabilities: take column 1 which corresponds to 'positive' if classes_ are sorted as ['negative','positive']\n",
    "    # Find index of 'positive' robustly:\n",
    "    classes = list(pipe.named_steps['clf'].classes_)\n",
    "    pos_idx = classes.index('positive')\n",
    "    y_prob = pipe.predict_proba(X_test)[:, pos_idx]\n",
    "    y_test_binary = (y_test == \"positive\").astype(int)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    prec, rec, f1, _ = precision_recall_fscore_support(y_test, y_pred, average=\"binary\", pos_label=\"positive\")\n",
    "    auc = roc_auc_score(y_test_binary, y_prob)\n",
    "\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(f\"Accuracy: {acc:.3f} | Precision: {prec:.3f} | Recall: {rec:.3f} | F1: {f1:.3f} | ROC-AUC: {auc:.3f}\")\n",
    "    print(\"\\nClassification report:\\n\", classification_report(y_test, y_pred))\n",
    "    return y_test_binary, y_prob\n",
    "\n",
    "y_test_bin_lr, y_prob_lr = evaluate_model(\"Logistic Regression\", logreg_pipe, X_test, y_test)\n",
    "y_test_bin_rf, y_prob_rf = evaluate_model(\"Random Forest\", rf_pipe, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbb3be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Plot ROC curves side by side ===\n",
    "fpr1, tpr1, _ = roc_curve(y_test_bin_lr, y_prob_lr)\n",
    "fpr2, tpr2, _ = roc_curve(y_test_bin_rf, y_prob_rf)\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(fpr1, tpr1, label=f\"LogReg (AUC={roc_auc_score(y_test_bin_lr, y_prob_lr):.3f})\")\n",
    "plt.plot(fpr2, tpr2, label=f\"RandomForest (AUC={roc_auc_score(y_test_bin_rf, y_prob_rf):.3f})\")\n",
    "plt.plot([0,1], [0,1], 'k--', label=\"Chance\")\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curve — Pipelines\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9ff6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature names from the TF-IDF inside the pipelines\n",
    "feat_names_lr = logreg_pipe.named_steps['tfidf'].get_feature_names_out()\n",
    "feat_names_rf = rf_pipe.named_steps['tfidf'].get_feature_names_out()\n",
    "\n",
    "# Sanity check: both tfidf steps share the same config; feature lists should match\n",
    "assert np.array_equal(feat_names_lr, feat_names_rf), \"TF-IDF vocab differs between pipelines.\"\n",
    "feature_names = feat_names_lr\n",
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e540451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Logistic Regression: top positive/negative coefficients ---\n",
    "coefs = logreg_pipe.named_steps['clf'].coef_[0]\n",
    "\n",
    "topN = 25  # how many to show\n",
    "top_pos_idx = np.argsort(coefs)[-topN:][::-1]   # largest -> smallest\n",
    "top_neg_idx = np.argsort(coefs)[:topN]          # most negative -> less negative\n",
    "\n",
    "top_pos = pd.DataFrame({\n",
    "    \"feature\": feature_names[top_pos_idx],\n",
    "    \"coef\": coefs[top_pos_idx]\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "top_neg = pd.DataFrame({\n",
    "    \"feature\": feature_names[top_neg_idx],\n",
    "    \"coef\": coefs[top_neg_idx]\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(\"Top positive LR features (push to 'positive')\")\n",
    "display(top_pos)\n",
    "print(\"\\nTop negative LR features (push to 'negative')\")\n",
    "display(top_neg)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1,2,1)\n",
    "plt.barh(top_pos[\"feature\"][::-1], top_pos[\"coef\"][::-1])\n",
    "plt.title(\"LR: Top Positive Coefficients\")\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.barh(top_neg[\"feature\"][::-1], top_neg[\"coef\"][::-1])\n",
    "plt.title(\"LR: Top Negative Coefficients\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10bf2cf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Random Forest: top feature importances ---\n",
    "rf_importances = rf_pipe.named_steps['clf'].feature_importances_\n",
    "topN = 25\n",
    "top_rf_idx = np.argsort(rf_importances)[-topN:][::-1]\n",
    "\n",
    "top_rf = pd.DataFrame({\n",
    "    \"feature\": feature_names[top_rf_idx],\n",
    "    \"importance\": rf_importances[top_rf_idx]\n",
    "}).reset_index(drop=True)\n",
    "\n",
    "print(\"Top RF feature importances\")\n",
    "display(top_rf)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(6, 8))\n",
    "plt.barh(top_rf[\"feature\"][::-1], top_rf[\"importance\"][::-1])\n",
    "plt.title(\"Random Forest: Top Feature Importances\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31ceb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Save both pipelines ===\n",
    "joblib.dump(logreg_pipe, 'logreg_text_pipeline.pkl')\n",
    "joblib.dump(rf_pipe, 'rf_text_pipeline.pkl')\n",
    "\n",
    "# === Load & test on a sample ===\n",
    "loaded_lr = joblib.load('logreg_text_pipeline.pkl')\n",
    "loaded_rf = joblib.load('rf_text_pipeline.pkl')\n",
    "\n",
    "sample_text = \"Very tasty and fresh\"\n",
    "print(\"LR Prediction:\", loaded_lr.predict([sample_text])[0], \n",
    "      \" | Prob positive:\", loaded_lr.predict_proba([sample_text])[0][ list(loaded_lr.named_steps['clf'].classes_).index('positive') ])\n",
    "\n",
    "print(\"RF Prediction:\", loaded_rf.predict([sample_text])[0],\n",
    "      \" | Prob positive:\", loaded_rf.predict_proba([sample_text])[0][ list(loaded_rf.named_steps['clf'].classes_).index('positive') ])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
